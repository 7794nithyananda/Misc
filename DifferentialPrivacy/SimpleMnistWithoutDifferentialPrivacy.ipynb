{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is a modification of https://github.com/tensorflow/privacy/blob/master/tutorials/Classification_Privacy.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XAVN6c8prKOL"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "SassPC7WQAUO"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KwDK47gfLsYf"
   },
   "source": [
    "# Implement Differential Privacy with TensorFlow Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  \n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/privacy/blob/master/tutorials/Classification_Privacy.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00fQV7e0Unz3"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUphKzYu01O9"
   },
   "source": [
    "This tutorial uses [tf.keras](https://www.tensorflow.org/guide/keras) to train a convolutional neural network (CNN) to recognize handwritten digits with the SGD optimizer provided by the TensorFlow Privacy library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ijJYKVc05DYX"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKuHPYQCsV-x"
   },
   "source": [
    "First, set this notebook's runtime to use a GPU, under Runtime > Change runtime type > Hardware accelerator. Then, begin importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ef56gCUqrdVn"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 1.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_fVhfUyeI3d"
   },
   "source": [
    "Install TensorFlow Privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mU1p8N7M5Mmn"
   },
   "source": [
    "## Load and pre-process the dataset\n",
    "\n",
    "Load the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset and prepare the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1ML23FlueTr"
   },
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "train_data, train_labels = train\n",
    "test_data, test_labels = test\n",
    "\n",
    "train_data = np.array(train_data, dtype=np.float32) / 255\n",
    "test_data = np.array(test_data, dtype=np.float32) / 255\n",
    "\n",
    "train_data = train_data.reshape(train_data.shape[0], 28, 28, 1)\n",
    "test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)\n",
    "\n",
    "train_labels = np.array(train_labels, dtype=np.int32)\n",
    "test_labels = np.array(test_labels, dtype=np.int32)\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "assert train_data.min() == 0.\n",
    "assert train_data.max() == 1.\n",
    "assert test_data.min() == 0.\n",
    "assert test_data.max() == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVDcswOCtlr3"
   },
   "source": [
    "## Define and tune learning model hyperparameters\n",
    "Set learning model hyperparamter values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E14tL1vUuTRV"
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXNp_25y7JP2"
   },
   "source": [
    "one existing hyperamater that you must tune:\n",
    "\n",
    "1. `learning_rate` (float) - This hyperparameter already exists in vanilla SGD. The higher the learning rate, the more each update matters. If the updates are noisy (such as when the additive noise is large compared to the clipping threshold), a low learning rate may help the training procedure converge. \n",
    "\n",
    "Use the hyperparameter values below to obtain a reasonably accurate model (95% test accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVw_r2Mq7ntd"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wXAmHcNOmHc5"
   },
   "source": [
    "## Build the learning model\n",
    "\n",
    "Define a convolutional neural network as the learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCOo8aOLmFta"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, 8,\n",
    "                           strides=2,\n",
    "                           padding='same',\n",
    "                           activation='relu',\n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPool2D(2, 1),\n",
    "    tf.keras.layers.Conv2D(32, 4,\n",
    "                           strides=2,\n",
    "                           padding='valid',\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 1),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FT4lByFg-I_r"
   },
   "source": [
    "Define the optimizer and loss function for the learning model. Compute the loss as a vector of losses per-example rather than as the mean over a minibatch to support gradient manipulation over each training point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LI_3nXzEGmrP"
   },
   "source": [
    "## Compile and train the learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z4iV03VqG1Bo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 2/15\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 3/15\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 4/15\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 5/15\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 6/15\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 7/15\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 8/15\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 9/15\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 10/15\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 11/15\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 12/15\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 13/15\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 14/15\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n",
      "Epoch 15/15\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3619 - accuracy: 0.0993 - val_loss: 2.3579 - val_accuracy: 0.1032\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs=epochs, validation_data=(test_data, test_labels), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "history dict: {'loss': [2.3618500232696533, 2.3618509769439697, 2.3618507385253906, 2.3618509769439697, 2.3618507385253906, 2.3618509769439697, 2.3618509769439697, 2.3618507385253906, 2.3618509769439697, 2.3618507385253906, 2.3618509769439697, 2.3618509769439697, 2.3618507385253906, 2.3618507385253906, 2.3618505001068115], 'accuracy': [0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333, 0.09929999709129333], 'val_loss': [2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131, 2.357949733734131], 'val_accuracy': [0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311, 0.10320000350475311]}\n"
     ]
    }
   ],
   "source": [
    "print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classification_Privacy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
